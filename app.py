from flask import Flask, request, jsonify
from flask_cors import CORS
import os
import json
import numpy as np
import faiss
import requests
import google.generativeai as genai

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ FLASK SETUP â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app = Flask(__name__)

CORS(
    app,
    resources={r"/ask": {"origins": ["https://cosmic-crostata-1c51df.netlify.app"]}},
    methods=["GET", "POST", "OPTIONS"],
    allow_headers=["Content-Type"]
)

@app.after_request
def add_cors_headers(response):
    response.headers["Access-Control-Allow-Origin"] = "https://cosmic-crostata-1c51df.netlify.app"
    response.headers["Access-Control-Allow-Methods"] = "GET, POST, OPTIONS"
    response.headers["Access-Control-Allow-Headers"] = "Content-Type"
    return response

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ PROMÄšNNÃ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
index = None
chunks = None
chat_histories = {}

# ğŸ” API klÃ­Äe
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
GROG_API_KEY = os.getenv("GROG_API_KEY")

# ğŸ” Funkce pro embedding dotazu pÅ™es Gemini
def get_embedding(text):
    response = genai.embed_content(
        model="models/embedding-001",
        content=text,
        task_type="retrieval_query"
    )
    return np.array([response["embedding"]], dtype="float32")

# ğŸ’¬ Funkce pro volÃ¡nÃ­ Grog API (Llama 3.3 70B)
def call_llama(system_prompt, user_message):
    url = "https://api.groq.com/openai/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {GROG_API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": "llama3-70b-8192",
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_message}
        ],
        "temperature": 0.2,
        "max_tokens": 800
    }
    response = requests.post(url, headers=headers, json=payload)
    if response.status_code != 200:
        raise Exception(f"Grog API chyba: {response.status_code}, {response.text}")
    result = response.json()
    return result["choices"][0]["message"]["content"].strip()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ API ENDPOINT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.route("/ask", methods=["POST"])
def ask():
    global index, chunks, chat_histories

    data = request.get_json()
    question = data.get("question", "")
    profile = data.get("profileName", "unknown").lower()

    if index is None:
        index = faiss.read_index("faiss.index")
        with open("chunks.json", "r") as f:
            chunks = json.load(f)

    query_embedding = get_embedding(question)
    D, I = index.search(query_embedding, k=5)
    relevant_chunks = [chunks[i] for i in I[0]]
    context = "\n".join(relevant_chunks)

    chat_histories.setdefault(profile, []).append(f"UÅ¾ivatel: {question}")
    chat_histories[profile] = chat_histories[profile][-3:]
    history_prompt = "\n".join(chat_histories[profile])

    system_prompt = f"""Jsi El_KapitÃ¡n â€“ bÃ½valÃ½ zÃ¡vodnÃ­k a teÄ trenÃ©r bÄ›Å¾eckÃ©ho lyÅ¾ovÃ¡nÃ­. TrÃ©nujeÅ¡ juniory z Prahy, kteÅ™Ã­ to myslÃ­ vÃ¡Å¾nÄ›, ale nÄ›kdy potÅ™ebujÃ­ trochu postrÄit. MluvÃ­Å¡ uvolnÄ›nÄ›, obÄas nespisovnÄ›, jako kÃ¡moÅ¡ nebo starÅ¡Ã­ parÅ¥Ã¡k z tÃ½mu. UmÃ­Å¡ si udÄ›lat srandu, ale zÃ¡roveÅˆ mluvÃ­Å¡ vÄ›cnÄ›. TvÅ¯j styl je pÅ™irozenÃ½, pÅ™Ã­mÃ½ a srozumitelnÃ½ â€“ bez zbyteÄnÃ½ omÃ¡Äky.

TvÅ¯j hlavnÃ­ ÃºÄel je odpovÃ­dat na otÃ¡zky ohlednÄ› trÃ©ninku, vysvÄ›tlovat principy, rozebÃ­rat chyby a radit. Pokud tÄ› nÄ›kdo poÅ¾Ã¡dÃ¡ o konkrÃ©tnÃ­ trÃ©nink, navrhni ho. Jinak se soustÅ™eÄ na obsah otÃ¡zky. OdpovÃ­dÃ¡Å¡ struÄnÄ›, jasnÄ› a pÅ™Ã­mo.

NechrlÃ­Å¡ plÃ¡ny, pokud o nÄ› nejsi vÃ½slovnÄ› poÅ¾Ã¡dÃ¡n. VysvÄ›tli, poraÄ, zhodnoÅ¥.

NepouÅ¾Ã­vej formÃ¡tovÃ¡nÃ­, odkazy ani odstavce â€“ prostÄ› jako kdybys to psal do skupinovÃ©ho chatu tÃ½mu. 

OdpovÃ­dÃ¡Å¡ vÅ¾dy na poslednÃ­ zprÃ¡vu. PÅ™edchozÃ­ pouÅ¾Ã­vej jen jako kontext.

VedlejÅ¡Ã­ tÃ©mata jako ultra pravicovÃ¡ politika nebo dating komentuj jen tehdy, kdyÅ¾ s nimi pÅ™ijde uÅ¾ivatel. Nikdy je nezaÄÃ­nej sÃ¡m.

Na konci odpovÄ›di klidnÄ› pÅ™idej poznÃ¡mku, povzbuzenÃ­ nebo for. Ale nikdy neodvÃ¡dÄ›j pozornost od trÃ©ninku.

Zde je kontext pro inspiraci:

{context}

PoslednÃ­ zprÃ¡vy:
{history_prompt}
"""

    try:
        response_text = call_llama(system_prompt, question)
        return jsonify({"answer": response_text})
    except Exception as e:
        return jsonify({"answer": f"Chyba: {e}"})

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ RUN PRO RENDER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5000))
    app.run(host="0.0.0.0", port=port)
